{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MljSzHUHmob_",
        "outputId": "406f231e-0929-470d-db30-953bb956496a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.61)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.78.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-openai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iE0U55om3RR",
        "outputId": "32c68c02-c57f-4419-d221-15429dad3e94"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.61 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.61)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.78.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain-openai) (0.3.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain-openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain-openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain-openai) (4.13.2)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain-openai) (2.11.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.61->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain-openai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain-openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.61->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.61->langchain-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.61->langchain-openai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain-openai langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aonUaxICn4ew",
        "outputId": "0db8cbc1-6941-4fc8-ed93-ff20a592dfb6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.61 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.61)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.78.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain-openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain-openai) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain-openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain-openai) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.61->langchain-openai) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Xc70p1opTg3",
        "outputId": "378425b4-daa6-4724-eb7b-9bbdfd66f18a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.61)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.42)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "!sudo apt install -y pciutils\n",
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X453tHLRyTD7",
        "outputId": "22009b2a-d80e-4e84-de41-13c1436bd0e0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:5 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "100 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "pciutils is already the newest version (1:3.7.0-6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 100 not upgraded.\n",
            ">>> Cleaning up old version at /usr/local/lib/ollama\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m No NVIDIA/AMD GPU detected. Ollama will run in CPU-only mode.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "def run_ollama_serve():\n",
        "  subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "thread = threading.Thread(target=run_ollama_serve)\n",
        "thread.start()\n",
        "time.sleep(5)"
      ],
      "metadata": {
        "id": "Ilgwj1KfyalK"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull llama3.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fAHecWKybxe",
        "outputId": "fdf6a030-c124-4b44-c318-b05ec6a00693"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.agents.agent import AgentExecutor\n",
        "from langchain.tools import Tool\n",
        "from langchain.chat_models import ChatOpenAI\n"
      ],
      "metadata": {
        "id": "hK0VYMldnGMW"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Dict\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.tools import tool as FunctionTool\n",
        "from langchain_core.runnables import Runnable\n",
        "from langchain.memory import ChatMessageHistory, ConversationBufferMemory\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.vectorstores.utils import DistanceStrategy\n",
        "from langchain_core.vectorstores import VectorStoreRetriever\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.indexes import VectorstoreIndexCreator\n"
      ],
      "metadata": {
        "id": "W-VUuW0GnGPH"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnWcg-ucryFj",
        "outputId": "255b539e-8534-4214-b3e5-00cd775f9b70"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import Ollama"
      ],
      "metadata": {
        "id": "3D4Ynf0fx7dQ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "llm = Ollama(model=\"llama3.2\", temperature=0.5)\n",
        "\n",
        "embed_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "\n",
        "documents = [\n",
        "    Document(page_content=\"California employment law requires minimum $16/hour wage.\", metadata={\"type\": \"legal\", \"location\": \"California\"}),\n",
        "    Document(page_content=\"Startup technical roles typically take 45-60 days to fill.\", metadata={\"type\": \"metrics\", \"role\": \"technical\"}),\n",
        "    Document(page_content=\"Standard interview process: Phone screen -> Technical assessment -> Onsite -> Offer\", metadata={\"type\": \"process\"})\n",
        "]\n",
        "index = FAISS.from_documents(documents, embedding=embed_model)\n",
        "retriever = index.as_retriever()\n",
        "\n"
      ],
      "metadata": {
        "id": "8IYoTGOHnGR-"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(token_limit=1000)"
      ],
      "metadata": {
        "id": "Nhnx-lIGrlh8"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "@tool\n",
        "def generate_job_description(role: str, experience_level: str, company_values: List[str]) -> str:\n",
        "    \"\"\"Generate a job description for a given role and experience level with company values.\"\"\"\n",
        "    prompt = f\"\"\"Create a job description for: {role} ({experience_level} level)\n",
        "    Company values: {', '.join(company_values)}\n",
        "    Include: Responsibilities, Requirements, and Benefits sections\"\"\"\n",
        "    return str(llm.invoke(prompt).content)\n",
        "\n",
        "@tool\n",
        "def get_salary_benchmark(role: str, location: str, stage: str) -> Dict:\n",
        "    \"\"\"Fetch salary benchmark data (50th and 75th percentile) for the given role and location.\"\"\"\n",
        "    salary_data = {\n",
        "        \"CTO\": {\"50th\": 150000, \"75th\": 180000},\n",
        "        \"Product Manager\": {\"50th\": 120000, \"75th\": 140000}\n",
        "    }\n",
        "    return {\n",
        "        \"role\": role,\n",
        "        \"location\": location,\n",
        "        \"data\": salary_data.get(role, {\"50th\": 100000, \"75th\": 120000})\n",
        "    }\n",
        "\n",
        "@tool\n",
        "def create_interview_plan(role: str, level: str) -> Dict:\n",
        "    \"\"\"Create an interview process plan for the given role and level.\"\"\"\n",
        "    return {\n",
        "        \"role\": role,\n",
        "        \"level\": level,\n",
        "        \"process\": [\n",
        "            \"Initial phone screen (30 mins)\",\n",
        "            \"Technical assessment (1 hour)\",\n",
        "            \"Team interview (2 hours)\",\n",
        "            \"Culture fit interview (1 hour)\",\n",
        "            \"Reference checks\"\n",
        "        ],\n",
        "        \"estimated_time\": \"3-4 weeks\"\n",
        "    }\n",
        "\n",
        "@tool\n",
        "def check_compliance(plan: Dict, location: str) -> Dict:\n",
        "    \"\"\"Check legal compliance of the hiring plan in the given location.\"\"\"\n",
        "    compliance_rules = {\n",
        "        \"California\": [\"Minimum wage $16/hr\", \"Anti-discrimination laws\", \"Mandatory harassment training\"],\n",
        "        \"New York\": [\"Minimum wage $15/hr\", \"Salary history ban\", \"Paid family leave\"]\n",
        "    }\n",
        "    return {\n",
        "        \"location\": location,\n",
        "        \"requirements\": compliance_rules.get(location, [\"Standard US employment laws apply\"]),\n",
        "        \"issues\": []\n",
        "    }\n"
      ],
      "metadata": {
        "id": "khaw7t08qJ1N"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool as FunctionTool\n"
      ],
      "metadata": {
        "id": "KkM6kKjFs2qJ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tools = [\n",
        "    FunctionTool(\"generate_jd\", generate_job_description),\n",
        "    FunctionTool(\"get_salary\", get_salary_benchmark),\n",
        "    FunctionTool(\"create_interview\", create_interview_plan),\n",
        "    FunctionTool(\"check_compliance\", check_compliance),\n",
        "]\n"
      ],
      "metadata": {
        "id": "cF-ZIahVqJ6Z"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tools_list = [generate_job_description, get_salary_benchmark, create_interview_plan, check_compliance]\n",
        "\n",
        "# agent = initialize_agent(\n",
        "#     tools=tools_list,\n",
        "#     llm=llm,\n",
        "#     agent=AgentType.OPENAI_FUNCTIONS,\n",
        "#     memory=memory,\n",
        "#     verbose=True\n",
        "# )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6LAXr6EuT-1",
        "outputId": "c3ef9387-023b-45bf-9808-de957945754f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-1e2ffb0c3f93>:3: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "tools = [\n",
        "    FunctionTool(\"generate_jd\", generate_job_description),\n",
        "    FunctionTool(\"get_salary\", get_salary_benchmark),\n",
        "    FunctionTool(\"create_interview\", create_interview_plan),\n",
        "    FunctionTool(\"check_compliance\", check_compliance),\n",
        "]\n",
        "\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.OPENAI_FUNCTIONS,\n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "WRMsWHvT5GYU"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_hiring_plan(company_info: Dict):\n",
        "    needs_analysis = agent.invoke(\n",
        "        f\"Analyze hiring needs for {company_info['name']} \"\n",
        "        f\"in {company_info['industry']} with {company_info['team_size']} employees\"\n",
        "    )\n",
        "\n",
        "    role_priority = agent.invoke(\n",
        "        \"Based on this startup context, recommend role hiring priority:\\n\"\n",
        "        f\"{str(needs_analysis)}\\nConsider their funding stage: {company_info['stage']}\"\n",
        "    )\n",
        "\n",
        "    plan = {}\n",
        "    for role in [\"CTO\", \"Product Manager\"]:\n",
        "        plan[role] = {\n",
        "            \"job_description\": generate_job_description(role, \"senior\", company_info[\"values\"]),\n",
        "            \"salary_range\": get_salary_benchmark(role, company_info[\"location\"], company_info[\"stage\"]),\n",
        "            \"interview_process\": create_interview_plan(role, \"senior\")\n",
        "        }\n",
        "\n",
        "    compliance = check_compliance(plan, company_info[\"location\"])\n",
        "    return {\n",
        "        \"company\": company_info[\"name\"],\n",
        "        \"hiring_priority\": str(role_priority),\n",
        "        \"detailed_plan\": plan,\n",
        "        \"compliance_check\": compliance\n",
        "    }\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     company_profile = {\n",
        "#         \"name\": \"TechNova\",\n",
        "#         \"industry\": \"AI\",\n",
        "#         \"team_size\": 15,\n",
        "#         \"location\": \"California\",\n",
        "#         \"stage\": \"Series A\",\n",
        "#         \"values\": [\"innovation\", \"diversity\", \"agility\"]\n",
        "#     }\n",
        "\n",
        "#     print(\"Generating hiring plan...\")\n",
        "#     try:\n",
        "#         plan = create_hiring_plan(company_profile)\n",
        "#         print(\"\\nGenerated Hiring Plan:\")\n",
        "#         print(json.dumps(plan, indent=2))\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error generating plan: {e}\")\n",
        "\n",
        "#     print(\"\\nAsk HR questions (type 'exit' to quit):\")\n",
        "#     while True:\n",
        "#         try:\n",
        "#             user_input = input(\"\\nHR Question: \")\n",
        "#             if user_input.lower() == 'exit':\n",
        "#                 break\n",
        "#             response = agent.invoke(user_input)\n",
        "#             print(f\"\\nAssistant: {response}\")\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error processing question: {e}\")\n"
      ],
      "metadata": {
        "id": "_k7pudxSqJ8v"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "def ollama_run(prompt: str) -> str:\n",
        "    \"\"\"Run an Ollama model via CLI and get the output.\"\"\"\n",
        "    result = subprocess.run(\n",
        "        ['ollama', 'run', 'llama3.2', prompt],  # or your desired model name\n",
        "        capture_output=True,\n",
        "        text=True\n",
        "    )\n",
        "    if result.returncode != 0:\n",
        "        raise RuntimeError(f\"Ollama run failed: {result.stderr}\")\n",
        "    return result.stdout.strip()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    company_profile = {\n",
        "        \"name\": \"TechNova\",\n",
        "        \"industry\": \"AI\",\n",
        "        \"team_size\": 15,\n",
        "        \"location\": \"California\",\n",
        "        \"stage\": \"Series A\",\n",
        "        \"values\": [\"innovation\", \"diversity\", \"agility\"]\n",
        "    }\n",
        "\n",
        "    print(\"Generating hiring plan...\")\n",
        "    try:\n",
        "        plan = create_hiring_plan(company_profile)\n",
        "        print(\"\\nGenerated Hiring Plan:\")\n",
        "        print(json.dumps(plan, indent=2))\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating plan: {e}\")\n",
        "\n",
        "    print(\"\\nAsk HR questions (type 'exit' to quit):\")\n",
        "    while True:\n",
        "        user_input = input(\"\\nHR Question: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "        try:\n",
        "            response = ollama_run(user_input)\n",
        "            print(f\"\\nAssistant: {response}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing question: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Fa-R91hZ0it7",
        "outputId": "f8c30bcc-1b3b-4b1b-b1c1-0bd3f1362015"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating hiring plan...\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI'd be happy to help analyze the hiring needs for TechNova's AI team.\n",
            "\n",
            "**Current Team Structure:**\n",
            "To get started, I'll need some information about the current team structure. Can you please provide me with the following details:\n",
            "\n",
            "1. Number of employees currently working in the AI department\n",
            "2. Job titles and roles of each employee (e.g., Data Scientist, Engineer, Researcher, etc.)\n",
            "3. Key skills and areas of expertise that are currently represented by the team\n",
            "\n",
            "**Hiring Needs:**\n",
            "Based on our conversation, I'll provide some general suggestions for hiring needs. Please feel free to adjust or add to these based on your specific requirements:\n",
            "\n",
            "1. **Data Scientist:** With 15 employees, it's likely that the team is working on various projects and datasets. A Data Scientist can help with data analysis, modeling, and visualization.\n",
            "2. **Machine Learning Engineer:** As AI technology advances, the need for skilled engineers who can develop, deploy, and maintain AI models will increase.\n",
            "3. **Researcher/Scientist:** TechNova may be exploring new areas of AI research or developing cutting-edge technologies. A researcher/scientist can help drive innovation and advance the field.\n",
            "4. **DevOps Engineer:** With multiple projects and teams working on AI-related initiatives, a DevOps engineer can ensure smooth deployment, scalability, and maintenance of AI systems.\n",
            "5. **Project Manager:** To manage the growth and complexity of the team, a project manager can oversee multiple projects, coordinate with stakeholders, and ensure timely delivery.\n",
            "\n",
            "**Key Skills:**\n",
            "Based on industry trends and requirements, here are some key skills that TechNova's AI team may need to fill:\n",
            "\n",
            "1. Programming languages: Python, Java, C++, etc.\n",
            "2. Machine learning frameworks: TensorFlow, PyTorch, Scikit-learn, etc.\n",
            "3. Data analysis and visualization tools: Pandas, NumPy, Matplotlib, Seaborn, Tableau, Power BI, etc.\n",
            "4. Cloud platforms: AWS, Azure, Google Cloud, etc.\n",
            "5. AI/ML hardware: GPUs, TPUs, FPGAs, etc.\n",
            "\n",
            "**Growth Areas:**\n",
            "To stay competitive and innovative, TechNova's AI team may want to consider hiring for the following growth areas:\n",
            "\n",
            "1. **Explainable AI (XAI):** As AI becomes more pervasive, there is a growing need to understand how AI models make decisions.\n",
            "2. **Edge AI:** With the increasing demand for real-time processing and low-latency applications, edge AI expertise will become crucial.\n",
            "3. **Natural Language Processing (NLP):** NLP has many applications in areas like chatbots, sentiment analysis, and text classification.\n",
            "\n",
            "These are just some general suggestions based on industry trends and requirements. Can you please provide me with more specific information about TechNova's current team structure, hiring needs, and growth areas?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mBased on the provided context, I'll recommend a role hiring priority for TechNova's AI team.\n",
            "\n",
            "**Funding Stage:** Series A (typically indicates a growing company with some traction but still in the early stages of scaling)\n",
            "\n",
            "Considering the startup's growth stage and funding, I would prioritize roles that focus on:\n",
            "\n",
            "1. **Data Science and Machine Learning Engineering**: With 15 employees, it's likely that TechNova is working on various projects and datasets. A Data Scientist can help with data analysis, modeling, and visualization, while a Machine Learning Engineer can develop, deploy, and maintain AI models.\n",
            "2. **Cloud Platforms and DevOps Engineering**: As the team grows, they'll need to ensure smooth deployment, scalability, and maintenance of AI systems. A DevOps engineer can help with this, especially if TechNova plans to expand its cloud presence (e.g., AWS, Azure, Google Cloud).\n",
            "3. **Research and Development**: With a Series A funding stage, TechNova is likely exploring new areas of AI research or developing cutting-edge technologies. A Researcher/Scientist can help drive innovation and advance the field.\n",
            "\n",
            "These roles are crucial for TechNova's growth and success in the short-term (next 6-12 months). Focusing on these priorities will enable the team to:\n",
            "\n",
            "* Develop and deploy more effective AI models\n",
            "* Scale their cloud infrastructure and DevOps processes\n",
            "* Drive innovation and stay competitive in the rapidly evolving AI landscape\n",
            "\n",
            "While roles like Project Management, Explainable AI (XAI), and Edge AI are important for long-term growth, they can be prioritized after addressing the immediate needs of scaling and developing the core AI capabilities.\n",
            "\n",
            "**Recommendation:**\n",
            "\n",
            "1. 2-3 Data Scientists\n",
            "2. 1-2 Machine Learning Engineers\n",
            "3. 1 DevOps Engineer\n",
            "\n",
            "This combination will provide a solid foundation for TechNova's AI team, enabling them to develop and deploy effective AI models, scale their cloud infrastructure, and drive innovation in the field.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Error generating plan: BaseTool.__call__() takes from 2 to 3 positional arguments but 4 were given\n",
            "\n",
            "Ask HR questions (type 'exit' to quit):\n",
            "\n",
            "HR Question: Create a comprehensive job description and a structured interview plan for hiring an **AI Engineer** with expertise in the following areas:  - Machine Learning (ML) - Deep Learning - Large Language Models (LLMs) - Parameter-Efficient Fine-Tuning (PEFT) methods such as LoRA, Prefix Tuning, and Adapter modules  The output should include the following sections:  1. **Job Title:** AI Engineer – ML, Deep Learning, and LLM PEFT 2. **Job Summary:** A concise overview of the role and its impact. 3. **Key Responsibilities:** A bullet-point list of the engineer's day-to-day responsibilities. 4. **Required Qualifications:** Technical and soft skills, including years of experience. 5. **Preferred Qualifications:** Nice-to-have skills or experience. 6. **Benefits:** Brief overview of what the company offers (you can assume standard tech startup benefits). 7. **Interview Plan:** Break down the hiring process into stages such as:    - Phone screen    - Technical deep-dive (covering ML/DL fundamentals and LLM architecture understanding)    - Practical coding test or take-home assignment    - PEFT methodology case discussion or mini-project review    - Culture fit / cross-functional collaboration round  Make the tone technical, focused, and appealing to high-caliber AI talent.\n",
            "\n",
            "Assistant: **Job Title:** AI Engineer – ML, Deep Learning, and LLM PEFT\n",
            "\n",
            "**Job Summary:**\n",
            "\n",
            "We are seeking a highly skilled AI Engineer with expertise in Machine Learning (ML), Deep Learning, Large Language Models (LLMs), and Parameter-Efficient Fine-Tuning (PEFT) methods such as LoRA, Prefix Tuning, and Adapter modules. As an AI Engineer on our team, you will be responsible for developing and implementing cutting-edge models that drive business value through innovative applications of ML and DL. You will work closely with cross-functional teams to design, develop, and deploy models that meet the needs of our customers. If you have a passion for AI research and development, enjoy working in a fast-paced environment, and are excited about the prospect of shaping the future of AI, we encourage you to apply.\n",
            "\n",
            "**Key Responsibilities:**\n",
            "\n",
            "• Design, develop, and implement ML and DL models using popular frameworks such as PyTorch or TensorFlow\n",
            "• Collaborate with data scientists to identify business problems that can be addressed through AI solutions\n",
            "• Develop and maintain LLMs using transformer-based architectures and PEFT methods\n",
            "• Implement and integrate PEFT techniques into existing models for improved performance and efficiency\n",
            "• Conduct research on emerging trends in ML, DL, and PEFT methodologies and apply them to improve model performance\n",
            "• Work closely with software engineers to develop efficient and scalable deployment pipelines\n",
            "• Participate in code reviews and contribute to the growth of our open-source projects\n",
            "• Stay up-to-date with industry developments and advancements in AI\n",
            "\n",
            "**Required Qualifications:**\n",
            "\n",
            "* Master's degree or Ph.D. in Computer Science, Mathematics, Statistics, or related field\n",
            "* 3+ years of experience in AI research and development, with a focus on ML and DL\n",
            "* Strong background in Python programming and popular deep learning frameworks\n",
            "* Experience with large-scale model training and deployment\n",
            "* Excellent understanding of LLMs and PEFT methodologies\n",
            "* Strong analytical and problem-solving skills\n",
            "\n",
            "**Preferred Qualifications:**\n",
            "\n",
            "* Ph.D. in Computer Science or related field\n",
            "* 5+ years of experience in AI research and development, with a focus on ML and DL\n",
            "* Experience with research publications and conference presentations\n",
            "* Familiarity with knowledge graph-based architectures and natural language processing applications\n",
            "* Knowledge of industry-standard frameworks such as TensorFlow or PyTorch\n",
            "* Experience with large-scale model training and deployment using cloud platforms\n",
            "\n",
            "**Benefits:**\n",
            "\n",
            "We offer competitive salaries, comprehensive health insurance, 401(k) matching, paid time off, and a flexible work environment that encourages collaboration and creativity. Our team is passionate about making a positive impact through AI, and we're committed to supporting your growth and development as an engineer.\n",
            "\n",
            "**Interview Plan:**\n",
            "\n",
            "**Phone Screen (30 minutes)**\n",
            "\n",
            "* Introduction and icebreaker questions\n",
            "* Overview of the role and company\n",
            "* Questions to assess basic technical skills and experience\n",
            "\n",
            "**Technical Deep-Dive (60-90 minutes)**\n",
            "\n",
            "* Review of ML and DL fundamentals, including regression, classification, clustering, and neural networks\n",
            "* Discussion of LLM architectures, including transformer-based models and attention mechanisms\n",
            "* In-depth exploration of PEFT methodologies, including LoRA, Prefix Tuning, and Adapter modules\n",
            "* Questions to assess understanding of technical concepts and ability to apply them\n",
            "\n",
            "**Practical Coding Test or Take-Home Assignment (90-120 minutes)**\n",
            "\n",
            "* Design and implement a simple model using PyTorch or TensorFlow\n",
            "* Complete a take-home assignment that requires the application of PEFT methodologies to an LLM-based task\n",
            "* Evaluation of coding skills, problem-solving abilities, and ability to apply technical concepts\n",
            "\n",
            "**PEFT Methodology Case Discussion or Mini-Project Review (60-90 minutes)**\n",
            "\n",
            "* In-depth discussion of a case study or mini-project related to PEFT methodologies\n",
            "* Evaluation of the candidate's ability to analyze problems, design solutions, and implement them\n",
            "* Questions to assess understanding of PEFT methodology and ability to apply it to real-world problems\n",
            "\n",
            "**Culture Fit / Cross-Functional Collaboration Round (60-90 minutes)**\n",
            "\n",
            "* Introduction to the team and company culture\n",
            "* Discussion of project goals, expectations, and challenges\n",
            "* Evaluation of the candidate's ability to collaborate with cross-functional teams and adapt to changing priorities\n",
            "* Questions to assess fit with company values and work style\n",
            "\n",
            "HR Question: What is the salary benchmark for a CTO in San Francisco for a Series A startup\n",
            "\n",
            "Assistant: The salary benchmark for a CTO in San Francisco for a Series A startup can vary depending on several factors, such as the company's industry, size, stage, and culture. However, here are some general guidelines based on national averages and online sources:\n",
            "\n",
            "* According to Glassdoor, the average salary for a Chief Technology Officer (CTO) in San Francisco is around $236,000 per year.\n",
            "* Indeed.com reports an average salary of $260,000 per year for a CTO in San Francisco.\n",
            "* LinkedIn's salary data suggests an average salary range of $180,000 to $280,000 per year for a CTO in San Francisco.\n",
            "* A survey by EY (Ernst & Young) found that the average salary for a CTO in the Bay Area is around $250,000 per year.\n",
            "\n",
            "For a Series A startup, the salary benchmark may be lower due to the typically smaller size and tighter budgets of these companies. However, it's essential to consider factors such as:\n",
            "\n",
            "* Industry: Startups in high-growth industries like fintech or healthcare might pay more than those in slower-growing sectors.\n",
            "* Experience: More experienced CTOs can command higher salaries, regardless of company stage.\n",
            "* Location: San Francisco is a highly competitive market, and salaries may be higher compared to other parts of the country.\n",
            "\n",
            "Assuming an average salary range for a Series A startup in San Francisco, here are some rough estimates:\n",
            "\n",
            "* For a relatively inexperienced CTO (5-10 years of experience), the salary could range from $150,000 to $200,000 per year.\n",
            "* For a mid-level CTO (10-20 years of experience), the salary could range from $200,000 to $250,000 per year.\n",
            "* For an experienced CTO (20+ years of experience), the salary could range from $250,000 to $300,000 per year.\n",
            "\n",
            "Keep in mind that these are rough estimates and may not reflect the actual salaries for specific companies or individuals. It's essential to research and understand the market conditions, company culture, and compensation expectations before making a hiring decision.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-2f4e4ae84a21>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nAsk HR questions (type 'exit' to quit):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nHR Question: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}